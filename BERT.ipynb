{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import accuracy_score, roc_curve\n",
    "from scipy.special import softmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_train = pd.read_csv(\"./Data/jigsaw-toxic-comment-train.csv\")\n",
    "comments_test  = pd.read_csv(\"./Data/validation.csv\")\n",
    "bias_train = pd.read_csv(\"./Data/jigsaw-unintended-bias-train.csv\")\n",
    "\n",
    "# drop unneeded columns right away\n",
    "bias_train = bias_train.iloc[:, :3]\n",
    "comments_train = comments_train.iloc[:, :3]\n",
    "# print (\"Train : \", len(comments_train), \"Test : \", len(comments_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0\n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_toxic_comment['comment_text'] = [train_data_toxic_comment['comment_text'].replace('\\\"', '')]\n",
    "# train_data_toxic_comment['comment_text'] = train_data_toxic_comment['comment_text'].replace('\\n', '')\n",
    "# train_data_toxic_comment['comment_text'] = train_data_toxic_comment['comment_text'].lower()\n",
    "\n",
    "\n",
    "# comments_train['comment_text'] = [sent.replace('\\\"', '') for sent in comments_train['comment_text']]\n",
    "# comments_train['comment_text'] = [sent.replace('\\n', '') for sent in comments_train['comment_text']]\n",
    "# comments_train['comment_text'] = [sent.lower()           for sent in comments_train['comment_text']]\n",
    "# comments_train['comment_text'] = [sent[:512]             for sent in comments_train['comment_text']]\n",
    "\n",
    "# comments_test['comment_text'] = [sent.replace('\\\"', '') for sent in comments_test['comment_text']]\n",
    "# comments_test['comment_text'] = [sent.replace('\\n', '') for sent in comments_test['comment_text']]\n",
    "# comments_test['comment_text'] = [sent.lower()           for sent in comments_test['comment_text']]\n",
    "# comments_test['comment_text'] = [sent[:512]             for sent in comments_test['comment_text']]\n",
    "\n",
    "# make_labels is similar to round but now we control what 0.5 is equal to\n",
    "def make_labels(x):\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i] = 0 if x[i] <= 0.5 else 1\n",
    "    return x\n",
    "\n",
    "# bias_train[\"toxic\"] = make_labels(bias_train[\"toxic\"])\n",
    "bias_train[\"toxic\"] = bias_train[\"toxic\"].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity fraction in train:  0.06285331763999694\n",
      "toxicity fraction in test:  0.15375\n"
     ]
    }
   ],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence = sentence.replace('\\\"', '')\n",
    "    sentence = sentence.replace('\\n', '')\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence[:256]\n",
    "    return sentence\n",
    "\n",
    "comments_train = pd.concat([comments_train, bias_train])\n",
    "\n",
    "comments_train['comment_text'] = comments_train['comment_text'].apply(preprocess)\n",
    "comments_test['comment_text']  = comments_test['comment_text'].apply(preprocess)\n",
    "print(\"toxicity fraction in train: \", comments_train['toxic'].value_counts()[1] / comments_train['toxic'].count())\n",
    "print(\"toxicity fraction in test: \", comments_test['toxic'].value_counts()[1] / comments_test['toxic'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity fraction in train:  0.5719361328710244\n",
      "toxicity fraction in test:  0.15375\n"
     ]
    }
   ],
   "source": [
    "# this cell is dealing with class imbalance\n",
    "# if you do not agree on the method - change it\n",
    "toxic = comments_train[comments_train[\"toxic\"] == 1]\n",
    "untoxic = comments_train[comments_train[\"toxic\"] == 0].sample(200000)\n",
    "\n",
    "comments_train = pd.concat((toxic, toxic, untoxic))\n",
    "# extra_toxic_comments = comments_train[comments_train[\"toxic\"] == 1].sample(10000)\n",
    "# comments_train = pd.concat([comments_train, extra_toxic_comments])\n",
    "\n",
    "print(\"toxicity fraction in train: \", comments_train['toxic'].value_counts()[1] / comments_train['toxic'].count())\n",
    "print(\"toxicity fraction in test: \", comments_test['toxic'].value_counts()[1] / comments_test['toxic'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences train :  467220 , test :  8000\n",
      "Example :  [CLS] mesaj sayfama yaptığınız müdahale vandalizm olarak kabul edilir. lütfen reklam yapmak için kullanıcıların sayfalarını değiştirmeyinizdelamorena  [SEP]\n"
     ]
    }
   ],
   "source": [
    "sentences_train = np.array(comments_train['comment_text'].values)\n",
    "sentences_test  = np.array(comments_test ['comment_text'].values)\n",
    "sentences_train = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences_train]\n",
    "sentences_test  = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences_test]\n",
    "\n",
    "labels_train = np.array(comments_train['toxic'])\n",
    "labels_test  = np.array(comments_test['toxic'])\n",
    "\n",
    "assert len(sentences_train) == len(labels_train)\n",
    "assert len(sentences_test)  == len(labels_test)\n",
    "\n",
    "print (\"Number of sentences train : \", len(sentences_train), \", test : \", len(sentences_test))\n",
    "print (\"Example : \", sentences_test[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 995526/995526 [00:00<00:00, 1336304.51B/s]\n",
      "100%|██████████| 467220/467220 [06:23<00:00, 1217.50it/s]\n",
      "100%|██████████| 8000/8000 [00:08<00:00, 988.25it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'co', '##cks', '##uck', '##er', 'before', 'you', 'pis', '##s', 'around', 'on', 'my', 'work', '[SEP]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pytorch_transformers import BertTokenizer, BertConfig\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "tokenized_texts_tr = [tokenizer.tokenize(sent) for sent in tqdm(sentences_train)]\n",
    "tokenized_texts_te = [tokenizer.tokenize(sent) for sent in tqdm(sentences_test)]\n",
    "print (tokenized_texts_tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 5505\n",
    "# print (\"Language : [\", comments_test['lang'][i], \"]\")\n",
    "# print (sentences_test[i])\n",
    "# print(tokenized_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_and_masks(tokenizer, tokenized_texts):\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tqdm(tokenized_texts)]\n",
    "    input_ids = pad_sequences(\n",
    "        input_ids,\n",
    "        maxlen=256,\n",
    "        dtype=\"long\",\n",
    "        truncating=\"post\",\n",
    "        padding=\"post\"\n",
    "    )\n",
    "    attention_masks = [[float(i>0) for i in seq] for seq in tqdm(input_ids)]\n",
    "    print (\"Dataset shape : \", input_ids.shape)\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 467220/467220 [00:26<00:00, 17402.92it/s]\n",
      "100%|██████████| 467220/467220 [01:38<00:00, 4760.44it/s]\n",
      " 16%|█▌        | 1257/8000 [00:00<00:00, 12560.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape :  (467220, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8000/8000 [00:00<00:00, 12578.73it/s]\n",
      "100%|██████████| 8000/8000 [00:01<00:00, 5400.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape :  (8000, 256)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "input_ids_tr, attention_masks_tr = ids_and_masks(tokenizer, tokenized_texts_tr)\n",
    "input_ids_te, attention_masks_te = ids_and_masks(tokenizer, tokenized_texts_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids_tr = [tokenizer.convert_tokens_to_ids(x) for x in tqdm(tokenized_texts_tr)]\n",
    "# input_ids_tr = pad_sequences(\n",
    "#     input_ids_tr,\n",
    "#     maxlen=512,\n",
    "#     dtype=\"long\",\n",
    "#     truncating=\"post\",\n",
    "#     padding=\"post\"\n",
    "# )\n",
    "# print (input_ids_tr.shape)\n",
    "# attention_masks_tr = [[float(i>0) for i in seq] for seq in input_ids_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids_te = [tokenizer.convert_tokens_to_ids(x) for x in tqdm(tokenized_texts_te)]\n",
    "# input_ids_te = pad_sequences(\n",
    "#     input_ids_te,\n",
    "#     maxlen=512,\n",
    "#     dtype=\"long\",\n",
    "#     truncating=\"post\",\n",
    "#     padding=\"post\"\n",
    "# )\n",
    "# print (input_ids_te.shape)\n",
    "# attention_masks_te = [[float(i>0) for i in seq] for seq in input_ids_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(input_ids_tr)\n",
    "train_labels = torch.tensor(labels_train, dtype=torch.long)\n",
    "train_masks  = torch.tensor(attention_masks_tr)\n",
    "\n",
    "test_inputs  = torch.tensor(input_ids_te)\n",
    "test_labels  = torch.tensor(labels_test, dtype=torch.long)\n",
    "test_masks   = torch.tensor(attention_masks_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    sampler=RandomSampler(train_data),\n",
    "    batch_size=32\n",
    ")\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    sampler=SequentialSampler(test_data),\n",
    "    batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import AdamW, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:00<00:00, 142152.81B/s]\n",
      "100%|██████████| 714314041/714314041 [01:11<00:00, 9934823.05B/s] \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14601\n"
     ]
    }
   ],
   "source": [
    "print (len(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nO3dd5wU9fnA8c/D0USpcqDSURCxISAKllhQAY1YYhRjokmMMUZN1Jgf1hh7iy22mERNjIo9oiIYC2JBmoKAUo4iHPWQ3jnu+f2xs8fc3uzu7O7Mltvn/XrxYnd2dua52d15Zr5VVBVjjDHFq16uAzDGGJNblgiMMabIWSIwxpgiZ4nAGGOKnCUCY4wpcpYIjDGmyFkiMEVPREpEZKOIdAxy3TTiuF1Eng16u8YkUz/XARiTKhHZ6HraBNgG7HSe/1pVn09le6q6E9gj6HWNKRSWCEzBUdXqE7GILAQuVtX3460vIvVVtTIbsRlTiKxoyNQ5ThHLSyLyoohsAC4Qkf4i8oWIrBWRZSLyiIg0cNavLyIqIp2d5/9xXn9XRDaIyHgR6ZLqus7rg0VkjoisE5G/ishnInKRz7/jDBGZ6cT8oYjs73rtehFZKiLrRWSWiBznLD9SRL50lq8QkfsCOKSmjrNEYOqqM4EXgObAS0Al8DugNXAUMAj4dYL3nw/cBLQCFgG3pbquiLQBXgaudfa7AOjnJ3gROQD4D3AFUAq8D7wlIg1E5EAn9t6q2gwY7OwX4K/Afc7y/YBX/ezPFDdLBKau+lRV31LVKlXdoqqTVHWCqlaq6nzgKeAHCd7/qqpOVtUdwPNArzTWPQ2YqqpvOq89CKzyGf95wEhV/dB5791AM+AIIkmtMXCgU+y1wPmbAHYA3URkT1XdoKoTfO7PFDFLBKauWux+IiI9ROQdEVkuIuuBW4lcpcez3PV4M4kriOOtu487Do2M8FjuI/boe79zvbfKeW87VZ0NXEPkb1jpFIHt5az6c6AnMFtEJorIEJ/7M0XMEoGpq2KH1f0bMAPYzyk2uRmQkGNYBrSPPhERAdr5fO9SoJPrvfWcbS0BUNX/qOpRQBegBLjLWT5bVc8D2gB/AV4TkcaZ/ymmLrNEYIpFU2AdsMkpf09UPxCUt4HeIvJDEalPpI6i1Od7XwZOF5HjnErta4ENwAQROUBEjheRRsAW599OABH5qYi0du4g1hFJiFXB/lmmrrFEYIrFNcCFRE6mfyNSgRwqVV0BnAs8AHwP7At8RaTfQ7L3ziQS7xNABZHK7dOd+oJGwL1E6huWAy2BG523DgG+dVpL3Q+cq6rbA/yzTB0kNjGNMdkhIiVEinx+pKqf5DoeY6LsjsCYEInIIBFp7hTj3ESkxc/EHIdlTA2WCIwJ19HAfCLFOIOAM1Q1adGQMdlkRUPGGFPk7I7AGGOKXMENOte6dWvt3LlzrsMwxpiCMmXKlFWq6tl8ueASQefOnZk8eXKuwzDGmIIiIt/Fe82KhowxpshZIjDGmCJnicAYY4qcJQJjjClylgiMMabIWSIwxpgiZ4nAGGOKXFElgjenLmHjtspch2GMMXmlaBLBtMVr+d2Iqdz4xvRch2KMMXmlaBLBJudOYMV6G/jRGGPciiYRGGOM8VY0icAG2zbGGG+hJgJndqbZIlImIsM9Xu8oIh+JyFci8rWIDAkrlu2VVc4+w9qDMcYUptASgTM/62PAYKAnMExEesasdiPwsqoeBpwHPB5WPDe9OQOA5eu2hrULYwrWhq07+O77TbkOw+RImHcE/YAyVZ2vqtuBEcDQmHUUaOY8bk5kYu9QlK/ZAsD6rTvC2oUxBeucJ8fzg/vG5joMkyNhJoJ2wGLX83JnmdstwAUiUg6MAq7w2pCIXCIik0VkckVFRRixGlPUZi3fkOsQTA6FmQi8SuNj62yHAc+qantgCPCciNSKSVWfUtW+qtq3tNRzgh3fbIpmY4ypKcxEUA50cD1vT+2in18CLwOo6nigMdA6xJis9RCws0rZVrkz12EYY/JEmIlgEtBNRLqISEMilcEjY9ZZBJwIICIHEEkEVvYTst8+/yX73zg612EYY/JEaIlAVSuBy4ExwLdEWgfNFJFbReR0Z7VrgF+JyDTgReAiVSu88aOqKv3DNHrm8gAjyUzFhm0cdfeHlK3cmOtQjClaofYjUNVRqtpdVfdV1TucZTer6kjn8TeqepSqHqqqvVT1vTDjcfYZ9i5CN2PJOrpeP4pxcwr/5mn0zOUsWbuFZz5bkOtQjClaRdOzOKrw0wBMXLAagA9nrcxxJMaYuqDoEoExxpiaLBEYY0yRK7pEsHaz9SzOK3WgzsaYQld0icDkJxsM0JjcKcpEMGH+93Ffq6rSOtGyyBhj/CrKRPDd6s1xX+t6/Siuf2NGFqMxYCVExuRSUSaCZF6cuCjXIRQPKxPKa99v3Mb736zIdRgmZJYITG7ZrUBeu+iZSVz878nVc36buskSgckLfm8M3vl6Gb1ufa96xjkTroWrIpPV7LSEXacVZyLIwnd6Z5Vy/5jZrN60PfydFZFb357J2s077LgaE6DiTARZMG5uBY9+VMaN/52e61AAeG78QjoPf4edGQxWF2vL9p08+L857NhpV+dlKzdaa7MCdMJfxlqdIJYIQrNzZ+SksG1Hfpwk7xw1CyDQeQge/WguD38wlxEZ/JDqwqlz3JwKBj7wMa9OKc91KCZF8ys2cd3r+XGxlkuWCEzatmyPJLltRV5eHx1Ce+bS9TmOxJj0FGcisBaLecM+CmNyrygTgZXlGmPMLqEmAhEZJCKzRaRMRIZ7vP6giEx1/s0RkbVhxhO1ZM2WjLexrXJnwkpSSzWmLinEa6ela7fw8PtzGTktdqr0cC36Pv7IBfkqtEQgIiXAY8BgoCcwTER6utdR1aucmcl6AX8FXg8rnnRsr6xi0EPj+KxsVa3X9r9xNKc98mla263cWcWYmcvtzoTUE2Y+HrJ86xy9ePXm4E5Gefa3pWLA3R/y4PtzuPLFr7K2zzenLuHY+z7i4wKbPTDMO4J+QJmqzlfV7cAIYGiC9YcRmbc4b5Sv2cys5Ru48b/eYw/NXrEh7nsT/X7++mEZv35uSsHPMKYB3vdIimecfDv55pNj7v2IY+/7KOPtfD5vFRu2Wo/iVEwvXwfAnOXxzw35KMxE0A5Y7Hpe7iyrRUQ6AV2AD+O8fomITBaRyRUVAWTaHJ9Fyp2iqbrSKUrsrJwRVeXbZfnX4ujpTxfmOgSTJWEmAq+zQ7xLyPOAV1XVs5G7qj6lqn1VtW9paWkogaVrxpJ1LHC64ZvcW7x6M4sTjC4bpnSL+v47dQmDH/6E92YuDzgiY/wJMxGUAx1cz9sD8WptziOLxUJBXsCe9tdPOf7+sbWWh1mUncm287GMPR3x/o5j7v2IY+7NvFgkFZl+nWY5xQjzKgrjgmLJ2i28MMF649Yl9UPc9iSgm4h0AZYQOdmfH7uSiOwPtATGhxhLzoRZapLKtutK6U1d+TsK2U/+/gULv9/MqYfsTfPdGuQ6HBOA0O4IVLUSuBwYA3wLvKyqM0XkVhE53bXqMGCE5qgJzcZtlVzwjwkJixMyCa2uXIH7UVWl3DN6FsvWZd48txAVy0ddXbdVLH9wEQjzjgBVHQWMill2c8zzW8KMwYu7hcroGcv5tGwVD74/hwd+3Kvmehlcfnq9c8aSdTTfrUGgrW3yyfQl63hi7DwmL1zNK5cOyHU4WWOV5abQFWXPYj+/2zBuUE7766c1yq8L/QQSe4iiY9bv2BleosvGHVa/O95nyMOfhL+jQpLn1y73jJ7FVS9NzXUYBatoEkHvji1SWv+tr5eFFElNqsoNb0zny0VrsrK/MGSSztI9sYeZQ1du2MY32WzOmecn2ULwxNh5vPHVklyHUa3Q7vqLJhGU1EvtzLF647aM9hf9GnwwayWdh78Td71tlVU8P2ERw576IqP9Rd329jd0va72/rJxJZ3JPgr85gjI/Binegwe+6iM3rf9L7OdmkAV6vc41DqCfOKuF3B/VrOX519HHr+8Tjz//HRBwvdk44uazj4KuVI9Vz/++8bMzsl+C/ijMnEUzR2B++zv/uH+/ZPEJ04I4Yuf6ZVjMFH4cv0b0znBo59EUPycRJ8bvzBnncSyqeCSYYFe/fqxbssOjr9/LDOXrst1KFlRPInAxauSdsmaLVS6RhNVMvueJ3qvutZJ5cdfubOKq16aytyV2RvH5IUJi5ifw57T67fu4KY3Z3L+P4IpOstLPr5oN785g399vjClzW7dEdxsdJ4KLXGlYPy871mwahMPvz83rfffMzo3d2vpKppEkOy3NmHBam5/59usxBIlce5S4pmzYiNvfLWEFycuTr5yHOFedaa+8WTxqJOb123eEXed9Vt38OxnCwJv6fXnt2amtH7aFYQ+3vbv8d/xp5Ez+ff4hb43O37+9+nFk0QdvhEITJBzg2dD8SQCH9/eT+buGtDuz299w/3vpZ/V82145WyWY6ezq0ziu+GNGdzy1jdMWLA6/Y14eOazhb7WC+rQ+jkGN7+ZWnLy482p+dPaptCl+jues2IDVVXKZ2Wr2LA1/sVO2IomEfgR+xm+nYUmpF4//iVrt1BVYFcUkLu5i9dujvR03V7kcyfH8pOgJi9cze9G7Gp/v3LD1vACMjVMW7yWkx8cx13vfstP/jGBy1/I3rwJsYomEaQ63n2q0j1xR68gtlVW8Y9P5jOvYiNH3f0hT46bF2B0/n25aA2z0xxL/a5Rs4BID+NMqCrPT/gup1dIUSvWF9aJcdO21OYP2BCz/utfuu8OvL/TmV6izF6+gRP/MjZhcV8xiA5HP9G5ky1buTFnsRRPIkixPD5VXa8f5ftHGK8s+/Z3vq3+coyfF075bjJnPf45pzw0Lq33zquIfJFT6VnsdSwmLVzDDW/M4KY4EwJl01mPf05Vlfqqf8iHVj9/eGVa9ePQe6772PzY2SurT3RRD/xvNvMqNjH0sfRm+DPBK5pE4Jbq3YHfH/i6LbuucPzsoZA6n6zetJ0/vTmD7ZVVNVpXhWGL09rle58T94R5Al6ydgtdrx+V+LY9jz7IOa5Z8zKPKvMtXPTMJH78t5oDC0eL8BYW4Ny+yWTyVYh3sfHxnAqmfBds/VesokkE7g8oWg66MfYKPsATSjYvDmcv35C0aGrz9syaEt7+9jf8a/x3HH//WPa74V22VQbTNDH2qvXbZetZnubopX5+hB/OWsGFT09MuYXRO9OzM+SIyS9Z+R0n+eJe+PREzn4i3FH6iycRuK5uoq1BDvrTmBrr7Mzw0vLMxz/L6P3pmLFkHac8NI7HPiqLu04QM6hVOolmydrISXrl+m08m2K7dj8GP/wJ//fa9FrLg/pB/uLZyXw8p4Iu143im6UB9SrPhzIhD3l0o1Jwiu3YFU0i8OO7DG9VV6zPbHyidCx1TszTyuNX0O4IoSjn1SnltZaFcj4M8Qc55JG6PcJo2A0kgsrO2yurQhntN5l8ayGVy8uJok0E0xavzXUIKQviKsXvl+3sJz7nlpH+2qyHUS7qpXJnFVX5ePVdhy4fs/2XrNq4je43vls9RtbGbZV8VrYqK/se8nBuKqvXbNpOmWt0gHw4F4WaCERkkIjMFpEyERkeZ50fi8g3IjJTRF4IL5aaz1dv9lcRCTV7jA6464NalV+pCudU5m+rscVh8Uz5bk2gRT9fl69N2DzOzwlovxveZdXG2p9brob8XbNpO1syrHspaAFkjWVrI1fl/3U6tf1+xFR+8o8JWWm2uyrDEYbTNejhcQx8IHnLvG2VOzM+1/gVWiIQkRLgMWAw0BMYJiI9Y9bpBlwHHKWqBwK/DzGetN/rvghdum5rreZwnvvzE5PHWhc+PTGFyHI3uU2quz390c8Y+MDHge0/2szWLfSiEMes5esZNX0Zh932P3746K6rSj/paPhrX3PxvyaHF1xIvJLt4tWbeeyjskCLdaLjaNXlBOu3CHnuio2+zjVBCPOOoB9QpqrzVXU7MAIYGrPOr4DHVHUNgKquDCuYQ9s3r7kgje+un45WM5zOVIk2H9TvJps5wE/ImVyZp/rOs5/4vNay9VnqgDbooU+47PkvgUgnoFQ+hhGTFvP+tytqLAvrfibs78fPnp7IfWNms3JDbq6sg1RVpTnvzZ/LUs8wE0E7wD06WrmzzK070F1EPhORL0RkUFjBdG/btMbzXz83JaX3r9q4zVdHqztHJR+4buS0pQApFb387eN5CVsG5UPReToxBHlHEz05h+WjJJMMffldZrPMBX3ejt3e+q07ajeZzkD0qt3P5z5uToXnaKiZFut9OndVIK2/jrjrA/rd+X7G2wlKtodLCTMReH2vYz/1+kA34DhgGPAPEak1p6SIXCIik0VkckVFRezLadmeYkuaDVv99hrG9xdzagqVRHe9O8tz7CM/J48wkkRQ9QeZFitM+W6N788mU48mSMQAs9IcmiNbDrnlPQ679b2E69z17qxQWpn97OmJ/Pmtb+K+nm6x3gX/nOC79VdVlcYdmrtiwzbv+qcUv55BXNh8XraK7je+y5QMLyxSEWYiKAc6uJ63B5Z6rPOmqu5Q1QXAbCKJoQZVfUpV+6pq39LS0rSCydYF8/j53zPkkU/4cNaK5CuTH3Obfl2+lofen5PSe9Zu9t+L2j0kr7v3tZvXNmr8qDwO05btOzn7ic/5OkHT2UIS+DfB46D6Gf4jabl0moEuWBW/sUA2fge3v/MtPW4a7SvR5aLmLXoMPnFaTWWrfgDCTQSTgG4i0kVEGgLnASNj1vkvcDyAiLQmUlQ0P4xgGpZk96OdX5HdyVwy+Rmd/uhnPJTmBBwQqUBPFMOTH+8aQG+5s+7WHTuTlsmOm1PB+jiJA6CyKvEP+vN5q1iZYuuTaHypiI6xlK5Mv5k/czUwcCfPoCvPPy9bRdfr3qkeqC7MOogw0sKLExcB4fSricpFf4gghDZnsapWisjlwBigBHhaVWeKyK3AZFUd6bx2soh8A+wErlXVUEZba9q4QdrvDfOzzbQTWrYqjBN9wZ8aN58WTRrELdf0OlH2uGk0w/p1ZPeGJQn3m8lUgef/fQKlTRsx6YaBvt8ze0XqxTt+5y0Iy7g5FUxauJrDO7cKZHvxPurHx87DK3cHcTUfTVo15xPfwOpN23ln+lL+88UiFt59asb78cv9F6kqVQol9XZFN718HT32bkqDkhCvpbN47Rrq5PWqOgoYFbPsZtdjBa52/oUqXxP18QnmA66qUu4ZM4sLjugUd51s/V2VSYoU7vU5Nd/GbTuq+xNEr9D8iB0u2a+KAmjREsRHeM6T42udKAu9n1uixhllKzfy039OCD0GEfjPF99x05szmXjDibRp2pj5FRv54aOfcm7fDrw0eTH3nH0w5x7eMeN95fIcFWoiMLvMT6P44Nvl6/nbx/PjDkmtChf/u7DapMcbPCvo/hCZFtfkQv6dt4M9MwV5ovvnpwtYlkYxXjpe/yrS2W3x6i20adqY1c6ouNFmwE+MnRdIIqgli4nBEoFPqZb9xZ7XTvhLap2ppi5ay8wlkdZH8a7G/cYU7xw7aeHqvOjeDumVrSZKHj9+Mr0emYVaxhvljj/IxJLssGyvrOKrRWs4ouueGe0nrKGpt1XurB7e3NRWtGMNpSrbnWY2bKvkj699Hci24v2Iz3lyPLe/k7zfQ7q+XLSGnVUaM+tVdsRrJmhiJCzzr5lKEt203TN6Fuc+9UV1h8p88+iHiZv+5gMbdC4LMq3Q+uWzk1JaP9uJI9+uZCcvXM1Zj3+esBOcH3n2ZxkXd16ITojjZzIhP8WAQX+fV/uc5Kh2HIGGkZoslhUWTyLI8APdlOLYJ9luPprI6BnLs77PaPltOq1wgpAv+WPrjp2s2riNL+Z/n9IgZ+meuOa5vndB17vE/oY2pdCz2M0dVbz3JttkLmfhTBRbJsc8l3VEVkdQAOJ9t/xeWT2YYmcxz+2EfGqN97f8JsGwEWH8cIL+K3/x7CQ+dyr7u7Te3dd7Rk1fxmXPf8mrl/anbwpNQjfEjLXk55zkVW4e9lWw1+bztYXT9p1VLPEY4BCCj9mKhrIgX64Qw+L19z3ywVw+DWhs90IrosmXeD93tfjyO1PchPmR96Ra3j5nReotpcIen8nN6yOJd+dz+9vxh6PIpnFzKpIW8y78fjPL1m2hz23/46lxu/rDptpbP5eKJhHURYnKUd+atpQH/jeHn/4ztWGtC0mmU4tGPTF2nq/BAv24+uWp1fM5D8+wsj/Vv+6TuTXH4Qp8ELsANjjsqS/4cNauQYY3bffuH/LR7MRjiuXiBiLR39//rg9r1Y889P7chMNpJ+sZn82rV0sEdUTsQHdXvPhVjiLJnv988V3G21BV7hk9a9eVXIY/vte/XMKH30ZOdCMmLU6ydvqiycYtk2FC3II4/4ybU1FjaJGo8fNDGTggqVSSWPmazVyS4ujE6ez33+OTfH/rSs/ifJJvrWpS4edLvHLDtpTH1UlFNo5eqp/Rt8viV0T7rdP4k8/pOHMh0cce5CQ/flSp+ipue3f6Ml6atIhR07PfQAEiQ4UjcPz+bdJ6/+pN2+M2d/54dgW9O7YMrNgxdhytujofQZ2xZK13ZVG+SXcYhnxxyC2Jh0iO9da02MFsvSUaxqPWVVkAV2EfzU5tfqV4CXD5+m21KoCjFq/29518/ctyrn9jekrxRLn33ef29+PWN7mjHzFpcc6SAMDPn53Ez59Jram3W6L5kh/+YG51M9mIPK3hToMlggKQDzcz2YghrETmt5I2KJMWpjeOfPTOL9qC6smP5zHoodpj7Zev8d/79uqXp/HChNpjOm2vrOKNr8o93xNNTBOCHgbZq/Namt+rXLUyytbcF9lWNIkgD86lafP75Xtvpr85ELJpXoIJ68OUduIK4IuyYNUmvkijLPzOUbPoPPwd1mzeVenodTd69D0fZRQfRFq0XPXStIy3A5HE8cnc5K3TJi6Mn1i+Ll8X6vDQ+Whurd9G7s5SRZMICtmi1f6uAO8ZPSuj/YQxZ2u+z9qVilTqMM576ouEr89avp4NW3d4DoUR1Hg7iaJNJ1HFMzZJC59E3Ff27qaXQXPPzZBsnoZ8uAP3sinEol9LBKba3z+J/0P0O+Na1PQcjzmzLY05Xx8fm73xaAY99AkH3/Iepzw0LvAewF6+XLQm5nn8wQZTPQ+uj1OPkapkvalf/7K8uplv0JPuRF3/+vSkHTCjI9v66Sn+7oza08v6FfsX/iLFYW5SYYnAVEs0dHOqNwthXt2F5fkvEs+PEMYJ+zuvq/8QLknPevzz6sdBj+OfSbipvPfql6eF/r3yU0/1cQp3QKkUvyU7FoHX2bgUTyLI09s9k19yMYd0spPbX97zN+mPX8nK88fNSb+oJ190Hv5O3NfyYZ7wfBNqIhCRQSIyW0TKRGS4x+sXiUiFiEx1/l0cZjwmfz37+cJch5BUroq7/prmEMpJOyzFkerUm0HVLaUyKF+qlroq3bds30llBhXTo2em3zw2WYX4H16ZxhNja3fEC1toHcpEpAR4DDgJKAcmichIVY0dROQlVb08rDiM8WvJ2i1s3RH/hxpvTuZ85befhZdsTfH52pe7mrC+OTX9eJP5wDWsRZ/b3+eEHul1OEvH9xu3sWzdVg5q15yhj34Wdz0FXp1SXuN5toR5R9APKFPV+aq6HRgBDA1xfwl13LNJrnZdMMKqgCsk2RyELZ8dfsf7vtedsTT9O6V0Whyt3JB5D3r3eEdhO/WRTzntr5+iqnyzbH3yN+RAmImgHeAebKXcWRbrbBH5WkReFZEOXhsSkUtEZLKITK6oSK/8ct/SPdJ6n6kb4s37bDI3Jsv9V54cW1gNEZY7Q7+8PDm8sacyFWYi8Lq8jL3beQvorKqHAO8D//LakKo+pap9VbVvaWlpwGGaYnB3hn0sTH7J1/kLEhnno9OdWzb/xDATQTngvsJvD9QoBFTV71U1Whj5d6BPiPGYJGYtz8/b1iBMW7yWa14Opidt2KaV5+e8vwZuSHPcJj9yOTBmmIlgEtBNRLqISEPgPGCkewUR2dv19HQgvJnUTVJ1/QTkrpg0Jh2Z9JRP9Qr/7a/T74yWqtBaDalqpYhcDowBSoCnVXWmiNwKTFbVkcCVInI6UAmsBi4KK566yFpDG1M4snliT1Wo8xGo6ihgVMyym12PrwOuCzOGuizdduLGFLoCrCLIa8XTs9gYYwpcWPUIlgiMMQWlEFsMBcVzbKoA+EoEIrKviDRyHh8nIleKSItQIjLGmASWr9/K9p11r4ZsU4KJ7qPC+qv91hG8BvQVkf2AfxJp/fMCMCSkuIwxxtM7eVzpmgk/Q5jkumioSlUrgTOBh1T1KmDvJO8xxhhTAPwmgh0iMgy4EHjbWdYgnJCMMcZ4CatoyG8i+DnQH7hDVReISBfgPyHFZIwxJot81RE4Q0dfCSAiLYGmqnp3mIEZY4ypKaxRKPy2GhorIs1EpBUwDXhGRB4IJyRjjDHZ5LdoqLmqrgfOAp5R1T7AwPDCMsYYU1tuWw3VdwaI+zG7KouNMcbUAX4Twa1EBo+bp6qTRKQrMDe8sIwxxmSL38riV4BXXM/nA2eHFZQxxpjacl1Z3F5E3hCRlSKyQkReE5H24YRkjDEmm/wWDT1DZFiJfYjMO/yWs8wYY0yW5LpDWamqPqOqlc6/ZwGbPNgYY+oAv4lglYhcICIlzr8LgO+TvUlEBonIbBEpE5HhCdb7kYioiPT1G7gxxphg+E0EvyDSdHQ5sAz4EZFhJ+ISkRLgMWAw0BMYJiI9PdZrSqTX8gT/YRtjjAmKr0SgqotU9XRVLVXVNqp6BpHOZYn0A8pUdb6qbgdGAEM91rsNuBfYmkrgxhhTbLbtSD5UdToymaHs6iSvtwMWu56XO8uqichhQAdVTdhJTUQuEZHJIjK5oqIirWCNMabQ3TtmVijbzSQRJJswzuv16kpvEakHPAhck2xHqvqUqvZV1b6lpVZHbYwpThUbtoWy3UwSQbKWTOVAB9fz9sBS1/OmwEHAWBFZCBwJjLQKY2OM8VYVUo+yhD2LRWQD3id8AZsuheYAABrGSURBVHZLsu1JQDdn7oIlwHnA+dEXVXUd0Nq1r7HAH1R1sq/IjTHGBCLhHYGqNlXVZh7/mqpqwiTiTG15OZExir4FXlbVmSJyq4icHtyf4N8fB+2fi90aY0wgwhpiwu/k9WlR1VHAqJhlN8dZ97gwYwFovUejsHdhjDGhCatoKJM6goJTIsnqt40xJn/leoiJOuG4/a3FkTGmcOV09NG6Yk8rGjLGFLAFqzaFst2iSgTGGGNqs0RgjDFFzhKBMcYUOUsExhhT5CwRGGNMkbNEYIwxRc4SgTHGFDlLBMYYU+QsERhjTJGzRGCMMUXOEoExxhQ5SwTGGFPkLBEYY0yRs0RgjDFFLtREICKDRGS2iJSJyHCP1y8VkekiMlVEPhWRnmHGY4wxprbQEoGIlACPAYOBnsAwjxP9C6p6sKr2Au4FHggrHmOMMd7CvCPoB5Sp6nxV3Q6MAIa6V1DV9a6nuxPeTGzGGGPiCHPy+nbAYtfzcuCI2JVE5LfA1UBD4ASvDYnIJcAlAB07dgw8UGOMKWZh3hF4zRRf64pfVR9T1X2B/wNu9NqQqj6lqn1VtW9pqc07bIwxQQozEZQDHVzP2wNLE6w/AjgjxHiMMcZ4CDMRTAK6iUgXEWkInAeMdK8gIt1cT08F5oYYjzHGGA+h1RGoaqWIXA6MAUqAp1V1pojcCkxW1ZHA5SIyENgBrAEuDCseY4wx3sKsLEZVRwGjYpbd7Hr8uzD3b4wxJjnrWWyMMUXOEoExxhQ5SwTGGFPkLBEYY0yRs0RgjDFFzhKBMcYUOUsExhhT5CwRGGNMgejedo9QtmuJwBhjCkT3tk1D2a4lAmOMKXKWCIwxpshZIjDGmCJXdIlg6s0ncfqh++Q6DGOMSZmI13xfmSu6RNCiSUOa79Yg12EYY0zeKLpEYIwxpiZLBMYYU+RCTQQiMkhEZotImYgM93j9ahH5RkS+FpEPRKRTmPHs2m829mKMMYUhtEQgIiXAY8BgoCcwTER6xqz2FdBXVQ8BXgXuDSseN9Vs7MUYYwpDmHcE/YAyVZ2vqtuBEcBQ9wqq+pGqbnaefgG0DzEeY4wxHsJMBO2Axa7n5c6yeH4JvOv1gohcIiKTRWRyRUVFgCEaY4wJMxF4lcR7FsqIyAVAX+A+r9dV9SlV7auqfUtLSwMM0RhjTJiJoBzo4HreHlgau5KIDARuAE5X1W0hxpNQ4wbWgMoYk9+O7NoqlO2GefabBHQTkS4i0hA4DxjpXkFEDgP+RiQJrAwxFk+3Dj2w+vEdZxxc/fjxn/TOdijGGJNUWKMihJYIVLUSuBwYA3wLvKyqM0XkVhE53VntPmAP4BURmSoiI+NsLjRNG9UH4Ow+u+qp998rnKFejTEmH9UPc+OqOgoYFbPsZtfjgWHu34+P/3g8G7bu8HytYf16bK+synJExhiTXaEmgny1V/PGALTavWH1Py/W78wYUwyKsob018d25dHzD+PUg/f2fH1vJ1Fcfvx+2QzLGGMSCqsvbFEmgvol9TjtkH3iDunapGF9Ft59Kmf1sf5txpi6rygTgV+JioYalgR76H5+VOdAt2eMMX5ZIkjDNSd1586zIs1NY5tztWuxW1rb/NMPD0y+kjGmqIU1TpolgjT069KKBiXe9wuN6mfvkO7XZo+s7csYkwcsEeSPI7ruGfe1hllMBNcP6ZG1fRlj6i5LBAn4mbcgNkF32rNJ9ePTDvFulRQr3t1FVEm91Bqy7tWscUrrBy3VeNMxtNc+zL9zSOj7MSafaEi3BJYIAvTIsMO4/5xDq583SzA38rHddw2e9+n/nQDAKQe29Vy3bdNGnsslTnX2XWcd7LkcdvWkDtMeWdgHQL0sJBxj8onVEWTBP37Wl9d+M6D6eaKWQSf0aEOvDi24amC36mWnH7oPTRs34JdHd0m4n8+Gn8C/f9Gv+nlb5wq+Yf0Sz/UP7dDCV/xRh3eJPzDVg+f2Smlbxpj8Yf0IsmBgz7b06dSy+vmeezRi/7a7xh368Jof8MLFRwDQtHED/vvbo+haWrvC9qbTerLw7lPjNj+N17Jo+OCaZf43nxaZ0O2qk7oDcPsZB9V8g88L4kPbN69+3NFVdJVrB7Vrxr6lu6f13uP3bwPAwrtPDTKkuAYe0IbDO7dMvmIB+b3rIsYUN0sESTxwbqSoZ49G9elaugcD9mud9rbO6dOet684Ou7rsQnixAPasPDuU+netmmkg1vvRPP61LZ7wxLuOutg/v6zvmnFmy4/dSsvXXIkb19xDA3S7I9xxmGpHQu/4pU2tWzSkOd+eUTg+xt04F45284BezcLZN8mHP06176z15DKhiwRJNG4QaS4pk2ccnqAx87vzSXHdq21fN+Yu4X7zjmUg9rtujp/9PzDePKCPr5jadKwPn//WV8Oapf4B9ykQQk9927GX37ci2H9OtImx5XHXlo08R7fyS3oOSK6t03e3Hbmnwd5LhfZ9V0I0uM/6Z3RXc1rv+nPg+ceyr3nHJLW+ztl+Q7xqP3it7gzNXndvVvRUB479ZC9uX7IAbWWXzSgMy9dcmTc9512yD4MOii1K7mTeral1e6RpBTvwrtePWHU747x3HaDkno0aRj8Cc3t2G6ZzyL33lXHxq0MD9NuPo/NZcftG8j+/Nw9JXPmYe1p1jh+w4REDve46vTyoyTDrVw1sLuv7Tx/8ZG8+KsjeeHiI7j2lP19vcetfhE1EPCc4tEqiwtPvXrCEV33ZNqfTmban07OdTgAdGm9e8Iv08fXHpfyNh/48aE1nt+X5tVpVLQ4LN2T5JUndgs82cUmpT8O6sGeuzfk/CM6BrofP5o2zv6gwZ0DvHPov++eDNivNb9NcVDHiTecyJQbTwosDrOLJYIkos0te6XYcset+W4NaJ6gKWmqwionTNdZvdvzH1f5eaM4rZ/cUj3Jz71jMB9c8wNf6/ZwTSw05vfHVj/u0yn9af684p1y00nceebBnsV7D5/nr3VW7MCHfsrt3e/Il69CoyxM9dqmaWOaN/H/O3oohy3kBuy7p+/+PJf+IPHd5bl9d834W5D9CERkkIjMFpEyERnu8fqxIvKliFSKyI/CjCVdbZo15u0rjq4eWyifxBs91cvVJ3X3VT5b6tSFlLrqRNxfxHiO7lazEj3ZUBstnMTo90TWoKRerTqXWF1b126B1L7lrgr44YN70HqP+HU96fIqgkvls3Hr2Cq9sarcvEpP3v3dMRlt86gEjSQu7N+JiwZ0Tvj+Jy/oXaOPTTa4WwBmQ+ydsV8XH5O4uXnvTi12fW8LrWhIREqAx4DBQE9gmIj0jFltEXAR8EJYcQThoHbNQ6koTFdLp6K1Uf169EvQZ8DtyhO78fzFNesrfhNTzj3qymNo0rA+b19xNKMzPHEk8uql/UOpwO7uaurrTjD9u+5J22aNaL5bAybfmN6keMnO62fGtGKKzmmRiacv8m7t5WeMqcGu5NS+5W5x7zSi23rygsTzdB/WsSUL7z6VKR7H7+qT9k/6+xh00N5J6xkSGXn5UZ7L00nsR8cktd0DKkY8q3fNv8/vtYD7u/rTIzvVel2Q6mbW6baySybMO4J+QJmqzlfV7cAIYKh7BVVdqKpfAzYfZIy+nVrG7W9w+5kH8efTD+SILq14+df9097HFSfULKONfnEPatecPTO8ch7iTPrz6qU142vcoB59fVZQpsv9+xOBFy85kgnX7zqBhTEw4AM/PpR5riEv3JWabZuldyxP6BHpaR7beurpiw7n9jMO4rzDO3gWWXbac/fqviewqz/KLT+MvQ6DS47pyiuX9mfQQbuGQ5ly40D2iZPI3N+LZjF1FWH1KG9YUo9D2qdfNBvr6pNrVmy/+psBzL69ZmuxRP1b3P1y4rl1qPdowsmGnbkttq+Q46mf9uWZnx9OyzizKWYqzETQDljsel7uLDM+vPqbAdSPk/2bNW7AhQM6p1384OXio7vU6Dznls5u7v3RIUy6YSB9O7fi1z/oyoB9U282GFb7kNgf6azbIieBDjHFMv/55RHc5JxEk9V7iEjcMZZKUjiAsZXS024+mUk31LwKb9GkIRcc2Ym7zz7E8zvy0q+PrL7K7NZmD052+hhcdFTtIoh69aRWy6E992jE65cdVaN40Eu01U+TRpFj447z21u9m+HGM/r3x9Ta3zHdWvPtrYOYc8fguO87qWfblJsZx34a9URqfb4fXHMcB+7jfRf15uVHM/XmmpXWP+hes6Xcfm2a1tjPLT/syYK7hvDo+ZE7r0PbN6f1HrtO6q/9ZgAfxqkDU5TmTRpUd6IMQ5iJwLP1U1obErlERCaLyOSKiooMw8pv2RiwLXpect+S3nhaz7hj93g1qbzyxMS9UhuU1Kv+YV83+AD+cWGkmCNZk9BHhh1Wa5n7B+NXokq1cw/vWKPtfuMGJXx100k1KpYhUu/xs/6duPz4/fhDGk0dozJ5b/MmDWiaYtPQNk13Xc0nykGJEtRezRtzQpITz0/7d2bh3adWF1e4vye7NSyhLMEJPFaPvZpxW0yCvn7IAQmb8068/kRuG3ogb19xNH9y3e0ku+PzewG1/17eF0ZQux/MST29xwmLuuioLtX7nXvHYF6/rGZRV59OLWuNUhDgdV5SYSaCcsBdy9geWJrOhlT1KVXtq6p9S0szb6Oezz685gdp9wT+v0E9OMTHbesrl/bn1z/o6ruJ5R9O3p+rBnav/oHN+PMpXH2Sv3bjybh7S9955sG1JvoBGHvt8dWPrz6pOxccWbPJ5rB+ka9Zr46R4oN2rgpiv30RWu7ekCYNaxdtNCipxx9O2T/lYg93Of5ZvdtnbSiMKD+tS8I+0cS7o40n1RZQbZo1pn5JPfZr05Sfe9ztZOq6wZG+Qc0a10/r82sep9Nkg5J6lNST6it8v31XwhRmIpgEdBORLiLSEDgPGBni/uqETnvunvTqIp7fHLcvIy+PP4RF1IH7NOe6wQf4vjLavVF9fjewW3W5d5DNV909sqMn9ESuPLEbt59RswXXHWcczOzbB3HJMV3531XHBlqenKoJ15/IpBsGJryKd7dkCtLPj+pcPdRE9Cq9VZwy5Y6tmiQcnDAXjuke7EVe9Ou9d/PGLLz71OqLJAEePLd2C5+TY353yaajjVePEnXtKZGLpXgNOu4862A+H35C3IuMcw+P/B4G7Jv+sDZ+hdYzRVUrReRyYAxQAjytqjNF5FZgsqqOFJHDgTeAlsAPReTPqmpzNqbo7SuO5stFa0LfT7LE8ddhh7F83VbP13ZrUMLZvdtzXszJ3r3NdOs86tUTGtWLXFV1c+o5Tuq5F29NW5qwqO2cPu3ZvH1nreUv/OqIlMr13dq6WkM9eUFvNm6rvX0vQ3vtw5tT498w33nmwVz/xvSEFwnu6U73Ld2DO888mJPjDG0+7o/Hey6PF1s27NGoPif2aMMHs1YCmd+x7Ll7I648sVt1/AMPaMvX5eto26wxh3ZoweMfzWPuyo3V6z/1s750Hv6O7+2PvOJofvbPiXyzbH31stcvG8A8Z5t7NIpcDMRrldSgpB77JJjatk+nVlm7kwy1i6KqjgJGxSy72fV4EpEiI5OBg9o1rzGGUa780KNYJ0pE+Eua7azTuQP5yzmHcsOQAxLOGHdfnHbtQV2BuVviJPPLo7vw5tSlHNy+OaNnLq/1+vlHdEy5F7PX+qN/fwwzlqz3WDu+/glm5Evm9csGUJpCC7RM55jYq1lj1mzeDkQSibsI8/Lj9+OCIzvVuktyJ5yRlx9VffEQ/e7E9pGJar1HIw7t0KJGIujdsSW9O0b6LxzeuSVXDezOT45M7XO788yD+XZZap9RprLfV93klTMPa+d74LFz+rbnmc8WZm06zkxaRTWsX4+9AmjLny2HtG/B6N8fQ/c2TblvzOzQ9tNjr2b02MvfqKNB9GKNnhTjufz4/WqcaO844yD+980KAFr5GJjQ7YvrTqRJoxIOv/19z9fr1ZMaScDrbtFdrLhbwxI++sNxafcJERF+l8ZQ37kYtsQSQZFLZaKam07tybWn7O9rCAlT2yuX9uecJ8fz474dWLVxG/8e/12N1/2eoLMtlXw89g/HsbXSX3EY1G5R1aZZY8ruGMzy9VtT7nSYauJ/8oI+PPfFd+yXoMd6F1dv9c+Hn8Dy9d5Fn9ls4RMGSwTGt3r1pEbLmiYNSzzL2I23wzu3Yu4dg6sr3f98und1WK8OLbJeNJCKwzq24KtFaz1f6+wxzEeq6pfUo33L+Hep1w/pwbTF6+K+/twvj2DExEVJm5F2br17dT8RP/ZpsVvCMv1CZonApO3ja4+vLo/NxMPn9WL0jNrl4vno/nMO5bkvvku+Yhx+hgj472+9h1PIF69dOiD5SiG65NjEg7T169LK99ArmTq/X0denLiI40Ls7JUNlghM2kqbNkra+9SPob3aMbRXYXQ6/1Gf9hmNmZPPTjmwLWNmrki6XqYVunXJwe2bZ72PSBhsGGqTt47vEbnKCmugLVPT337at8ZJrV+XSGuhbnGGHjF1h90RmLx1/zmH8MdTko9sacLxoz7tOaZb6xp9I0zdZJdaJm81ql9Ch1bZnVPX1GRJoDjYHYGJ64VfHcGKOM3ljDF1hyUCE1c2xjgxxuSeFQ0ZY0yRs0RgjDFFzhKBMcYUOUsExhhT5CwRGGNMkbNEYIwxRc4SgTHGFDlLBMYYU+QkyInIs0FEKoB0xwFuDawKMJywWJzBKYQYweIMUiHECNmPs5Oqlnq9UHCJIBMiMllV++Y6jmQszuAUQoxgcQapEGKE/IrTioaMMabIWSIwxpgiV2yJ4KlcB+CTxRmcQogRLM4gFUKMkEdxFlUdgTHGmNqK7Y7AGGNMDEsExhhT5IomEYjIIBGZLSJlIjI8y/vuICIfici3IjJTRH7nLG8lIv8TkbnO/y2d5SIijzixfi0ivV3butBZf66IXBhSvCUi8pWIvO087yIiE5x9viQiDZ3ljZznZc7rnV3buM5ZPltETgkhxhYi8qqIzHKOa/98O54icpXzec8QkRdFpHE+HEsReVpEVorIDNeywI6diPQRkenOex4REQkwzvucz/xrEXlDRFq4XvM8TvF++/E+iyDidL32BxFREWntPM/Z8UxIVev8P6AEmAd0BRoC04CeWdz/3kBv53FTYA7QE7gXGO4sHw7c4zweArwLCHAkMMFZ3gqY7/zf0nncMoR4rwZeAN52nr8MnOc8fhL4jfP4MuBJ5/F5wEvO457OMW4EdHGOfUnAMf4LuNh53BBokU/HE2gHLAB2cx3Di/LhWALHAr2BGa5lgR07YCLQ33nPu8DgAOM8GajvPL7HFafncSLBbz/eZxFEnM7yDsAYIh1gW+f6eCb8G4LeYD7+cw7iGNfz64DrchjPm8BJwGxgb2fZ3sBs5/HfgGGu9Wc7rw8D/uZaXmO9gGJrD3wAnAC87Xz5Vrl+fNXH0vmS93ce13fWk9jj614voBibETnJSszyvDmeRBLBYueHXd85lqfky7EEOlPzBBvIsXNem+VaXmO9TOOMee1M4HnnsedxIs5vP9H3Oqg4gVeBQ4GF7EoEOT2e8f4VS9FQ9EcZVe4syzrnlv8wYALQVlWXATj/t3FWixdvNv6Oh4A/AlXO8z2Btapa6bHP6nic19c564cdZ1egAnhGIkVY/xCR3cmj46mqS4D7gUXAMiLHZgr5dyyjgjp27ZzHYccL8AsiV8jpxJnoe50xETkdWKKq02JeysvjWSyJwKtMLevtZkVkD+A14Pequj7Rqh7LNMHyQIjIacBKVZ3iI5ZEr4V9vOsTuRV/QlUPAzYRKc6IJ+txOmXsQ4kUU+wD7A4MTrC/XB3LZFKNKyvxisgNQCXwfHRRivGE+dk3AW4AbvZ6OcV4snI8iyURlBMpr4tqDyzNZgAi0oBIEnheVV93Fq8Qkb2d1/cGVjrL48Ub9t9xFHC6iCwERhApHnoIaCEi9T32WR2P83pzYHUW4iwHylV1gvP8VSKJIZ+O50BggapWqOoO4HVgAPl3LKOCOnblzuPQ4nUqUk8DfqJOeUkaca4i/meRqX2JXABMc35L7YEvRWSvNOIM/XgCRVNHUJ9I5UsXdlUYHZjF/Qvwb+ChmOX3UbOC7l7n8anUrFCa6CxvRaRsvKXzbwHQKqSYj2NXZfEr1KxUu8x5/FtqVnC+7Dw+kJoVd/MJvrL4E2B/5/EtzrHMm+MJHAHMBJo4+/0XcEW+HEtq1xEEduyASc660crNIQHGOQj4BiiNWc/zOJHgtx/vswgizpjXFrKrjiCnxzNu/EFvMF//Eamtn0OkBcENWd730URu574Gpjr/hhApp/wAmOv8H/3gBXjMiXU60Ne1rV8AZc6/n4cY83HsSgRdibRcKHN+PI2c5Y2d52XO611d77/BiX82YbRygF7AZOeY/tf58eTV8QT+DMwCZgDPOSepnB9L4EUi9RY7iFxx/jLIYwf0df7mecCjxFTqZxhnGZGy9Ojv6Mlkx4k4v/14n0UQcca8vpBdiSBnxzPRPxtiwhhjilyx1BEYY4yJwxKBMcYUOUsExhhT5CwRGGNMkbNEYIwxRc4SgTEeRGSniEwVkWki8qWIDEiyfgsRuczHdseKSF5MWG5MlCUCY7xtUdVeqnookUHK7kqyfgsiI4gaU3AsERiTXDNgDUTGixKRD5y7hOkiMtRZ525gX+cu4j5n3T8660wTkbtd2ztHRCaKyBwROSa7f4oxtdVPvooxRWk3EZlKpMfv3kTGXQLYCpypquudyUa+EJGRRIZlOEhVewGIyGDgDOAIVd0sIq1c266vqv1EZAjwJyLjEhmTM5YIjPG2xXVS7w/8W0QOIjJEwJ0iciyRobrbAW093j8QeEZVNwOo6mrXa9FBB6cQGaPGmJyyRGBMEqo63rn6LyUybk0p0EdVdzijSzb2eJsQf7jgbc7/O7HfoMkDVkdgTBIi0oPISJbfExkeeqWTBI4HOjmrbSAyDWnUe8AvnLHpiSkaMiav2NWIMd6idQQQubq/UFV3isjzwFsiMpnI6JezAFT1exH5zJnA/F1VvVZEegGTRWQ7MAq4Pgd/hzFJ2eijxhhT5KxoyBhjipwlAmOMKXKWCIwxpshZIjDGmCJnicAYY4qcJQJjjClylgiMMabI/T/PvBFkRU2ieQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14601it [4:32:40,  1.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss на обучающей выборке: 0.29608\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Будем сохранять loss во время обучения\n",
    "# и рисовать график в режиме реального времени\n",
    "train_loss_set = []\n",
    "train_loss = 0\n",
    "\n",
    "\n",
    "# Обучение\n",
    "# Переводим модель в training mode\n",
    "model.train()\n",
    "\n",
    "\n",
    "for step, batch in tqdm(enumerate(train_dataloader)):\n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # если не сделать .zero_grad(), градиенты будут накапливаться\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "    train_loss_set.append(loss[0].item())  \n",
    "    \n",
    "    # Backward pass\n",
    "    loss[0].backward()\n",
    "    \n",
    "    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
    "    optimizer.step()\n",
    "\n",
    "    # Обновляем loss\n",
    "    train_loss += loss[0].item()\n",
    "    \n",
    "    # Рисуем график\n",
    "    clear_output(True)\n",
    "    plt.plot(train_loss_set)\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "  0%|          | 0/250 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "  0%|          | 1/250 [00:00<01:01,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 2/250 [00:00<01:01,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  1%|          | 3/250 [00:00<01:01,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 4/250 [00:01<01:01,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 5/250 [00:01<01:01,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  2%|▏         | 6/250 [00:01<01:01,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 7/250 [00:01<01:01,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      "  3%|▎         | 8/250 [00:02<01:00,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▎         | 9/250 [00:02<01:00,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 10/250 [00:02<00:59,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  4%|▍         | 11/250 [00:02<00:59,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▍         | 12/250 [00:03<00:59,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  5%|▌         | 13/250 [00:03<00:59,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 14/250 [00:03<00:58,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▌         | 15/250 [00:03<00:58,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      "  6%|▋         | 16/250 [00:03<00:58,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 17/250 [00:04<00:58,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "  7%|▋         | 18/250 [00:04<00:58,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 19/250 [00:04<00:57,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 20/250 [00:05<00:57,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      "  8%|▊         | 21/250 [00:05<00:57,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 22/250 [00:05<00:56,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      "  9%|▉         | 23/250 [00:05<00:56,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|▉         | 24/250 [00:05<00:56,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 25/250 [00:06<00:56,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 10%|█         | 26/250 [00:06<00:55,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 27/250 [00:06<00:55,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 11%|█         | 28/250 [00:06<00:55,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 29/250 [00:07<00:55,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 30/250 [00:07<00:55,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 12%|█▏        | 31/250 [00:07<00:54,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 32/250 [00:08<00:54,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 13%|█▎        | 33/250 [00:08<00:54,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▎        | 34/250 [00:08<00:54,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 35/250 [00:08<00:53,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 14%|█▍        | 36/250 [00:09<00:53,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▍        | 37/250 [00:09<00:53,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 15%|█▌        | 38/250 [00:09<00:52,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 39/250 [00:09<00:52,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▌        | 40/250 [00:09<00:52,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 16%|█▋        | 41/250 [00:10<00:52,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 42/250 [00:10<00:51,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 17%|█▋        | 43/250 [00:10<00:51,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 44/250 [00:10<00:51,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 45/250 [00:11<00:51,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 18%|█▊        | 46/250 [00:11<00:51,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 47/250 [00:11<00:51,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 19%|█▉        | 48/250 [00:12<00:51,  3.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|█▉        | 49/250 [00:12<00:50,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 50/250 [00:12<00:50,  3.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 20%|██        | 51/250 [00:12<00:50,  3.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 52/250 [00:13<00:50,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 21%|██        | 53/250 [00:13<00:50,  3.92it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 54/250 [00:13<00:49,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 55/250 [00:13<00:49,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 22%|██▏       | 56/250 [00:14<00:48,  3.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 57/250 [00:14<00:49,  3.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 23%|██▎       | 58/250 [00:14<00:48,  3.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▎       | 59/250 [00:14<00:48,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 60/250 [00:15<00:47,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 24%|██▍       | 61/250 [00:15<00:47,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▍       | 62/250 [00:15<00:47,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 25%|██▌       | 63/250 [00:15<00:46,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 64/250 [00:16<00:46,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▌       | 65/250 [00:16<00:46,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 26%|██▋       | 66/250 [00:16<00:45,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 67/250 [00:16<00:45,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 27%|██▋       | 68/250 [00:17<00:45,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 69/250 [00:17<00:45,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 70/250 [00:17<00:44,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 28%|██▊       | 71/250 [00:17<00:44,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 72/250 [00:18<00:44,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 29%|██▉       | 73/250 [00:18<00:44,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|██▉       | 74/250 [00:18<00:43,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 75/250 [00:18<00:43,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 30%|███       | 76/250 [00:19<00:43,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 77/250 [00:19<00:43,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 31%|███       | 78/250 [00:19<00:42,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 79/250 [00:19<00:42,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 80/250 [00:20<00:42,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 32%|███▏      | 81/250 [00:20<00:42,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 82/250 [00:20<00:41,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 33%|███▎      | 83/250 [00:20<00:41,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▎      | 84/250 [00:21<00:41,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 85/250 [00:21<00:41,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 34%|███▍      | 86/250 [00:21<00:40,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▍      | 87/250 [00:21<00:40,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 35%|███▌      | 88/250 [00:22<00:40,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 89/250 [00:22<00:40,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▌      | 90/250 [00:22<00:40,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 36%|███▋      | 91/250 [00:22<00:39,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 92/250 [00:23<00:39,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 37%|███▋      | 93/250 [00:23<00:39,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 94/250 [00:23<00:39,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 95/250 [00:23<00:38,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 38%|███▊      | 96/250 [00:24<00:38,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 97/250 [00:24<00:38,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 39%|███▉      | 98/250 [00:24<00:37,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|███▉      | 99/250 [00:24<00:37,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 100/250 [00:25<00:37,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 40%|████      | 101/250 [00:25<00:37,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 102/250 [00:25<00:37,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 41%|████      | 103/250 [00:25<00:36,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 104/250 [00:26<00:36,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 105/250 [00:26<00:36,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 42%|████▏     | 106/250 [00:26<00:35,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 107/250 [00:26<00:35,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 43%|████▎     | 108/250 [00:27<00:35,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▎     | 109/250 [00:27<00:35,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 110/250 [00:27<00:34,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 44%|████▍     | 111/250 [00:27<00:34,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▍     | 112/250 [00:28<00:34,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 45%|████▌     | 113/250 [00:28<00:34,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 114/250 [00:28<00:33,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▌     | 115/250 [00:28<00:33,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 46%|████▋     | 116/250 [00:29<00:33,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 117/250 [00:29<00:33,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 47%|████▋     | 118/250 [00:29<00:33,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 119/250 [00:29<00:32,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 120/250 [00:30<00:32,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 48%|████▊     | 121/250 [00:30<00:32,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 122/250 [00:30<00:31,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 49%|████▉     | 123/250 [00:30<00:31,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|████▉     | 124/250 [00:31<00:31,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 125/250 [00:31<00:31,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 50%|█████     | 126/250 [00:31<00:30,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 127/250 [00:31<00:30,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 51%|█████     | 128/250 [00:32<00:30,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 129/250 [00:32<00:30,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 130/250 [00:32<00:29,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 52%|█████▏    | 131/250 [00:32<00:29,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 132/250 [00:33<00:29,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 53%|█████▎    | 133/250 [00:33<00:29,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▎    | 134/250 [00:33<00:28,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 135/250 [00:33<00:28,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 54%|█████▍    | 136/250 [00:34<00:28,  3.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▍    | 137/250 [00:34<00:28,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 55%|█████▌    | 138/250 [00:34<00:28,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 139/250 [00:34<00:27,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▌    | 140/250 [00:35<00:27,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 56%|█████▋    | 141/250 [00:35<00:27,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 142/250 [00:35<00:26,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 57%|█████▋    | 143/250 [00:35<00:27,  3.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 144/250 [00:36<00:26,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 145/250 [00:36<00:26,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 58%|█████▊    | 146/250 [00:36<00:26,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 147/250 [00:36<00:25,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████▉    | 148/250 [00:37<00:25,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|█████▉    | 149/250 [00:37<00:25,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 150/250 [00:37<00:24,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 60%|██████    | 151/250 [00:37<00:24,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 152/250 [00:38<00:24,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 61%|██████    | 153/250 [00:38<00:24,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 154/250 [00:38<00:24,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 155/250 [00:38<00:23,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 62%|██████▏   | 156/250 [00:39<00:23,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 157/250 [00:39<00:23,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 63%|██████▎   | 158/250 [00:39<00:22,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▎   | 159/250 [00:39<00:22,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 160/250 [00:40<00:22,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 64%|██████▍   | 161/250 [00:40<00:22,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▍   | 162/250 [00:40<00:21,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 65%|██████▌   | 163/250 [00:40<00:21,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 164/250 [00:41<00:21,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▌   | 165/250 [00:41<00:21,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 66%|██████▋   | 166/250 [00:41<00:20,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 167/250 [00:41<00:20,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 67%|██████▋   | 168/250 [00:42<00:20,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 169/250 [00:42<00:20,  3.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 170/250 [00:42<00:20,  3.94it/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|██████▊   | 171/250 [00:42<00:19,  3.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 172/250 [00:43<00:19,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 69%|██████▉   | 173/250 [00:43<00:19,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|██████▉   | 174/250 [00:43<00:19,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 175/250 [00:43<00:18,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 70%|███████   | 176/250 [00:44<00:18,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 177/250 [00:44<00:18,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 71%|███████   | 178/250 [00:44<00:17,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 179/250 [00:44<00:17,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 180/250 [00:45<00:17,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 72%|███████▏  | 181/250 [00:45<00:17,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 182/250 [00:45<00:16,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 73%|███████▎  | 183/250 [00:45<00:16,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▎  | 184/250 [00:46<00:16,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 185/250 [00:46<00:16,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 74%|███████▍  | 186/250 [00:46<00:15,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▍  | 187/250 [00:46<00:15,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 75%|███████▌  | 188/250 [00:47<00:15,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 189/250 [00:47<00:15,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▌  | 190/250 [00:47<00:14,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 76%|███████▋  | 191/250 [00:47<00:14,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 192/250 [00:48<00:14,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 77%|███████▋  | 193/250 [00:48<00:14,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 194/250 [00:48<00:14,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 195/250 [00:48<00:13,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|███████▊  | 196/250 [00:49<00:13,  3.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 197/250 [00:49<00:13,  3.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 79%|███████▉  | 198/250 [00:49<00:13,  3.93it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|███████▉  | 199/250 [00:49<00:12,  3.95it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 200/250 [00:50<00:12,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 80%|████████  | 201/250 [00:50<00:12,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 202/250 [00:50<00:11,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 81%|████████  | 203/250 [00:50<00:11,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 204/250 [00:51<00:11,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 205/250 [00:51<00:11,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 82%|████████▏ | 206/250 [00:51<00:10,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 207/250 [00:51<00:10,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 83%|████████▎ | 208/250 [00:52<00:10,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▎ | 209/250 [00:52<00:10,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 210/250 [00:52<00:09,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 84%|████████▍ | 211/250 [00:52<00:09,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▍ | 212/250 [00:53<00:09,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 85%|████████▌ | 213/250 [00:53<00:09,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 214/250 [00:53<00:08,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▌ | 215/250 [00:53<00:08,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 86%|████████▋ | 216/250 [00:54<00:08,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 217/250 [00:54<00:08,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 87%|████████▋ | 218/250 [00:54<00:07,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 219/250 [00:54<00:07,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 220/250 [00:55<00:07,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 88%|████████▊ | 221/250 [00:55<00:07,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 222/250 [00:55<00:07,  3.96it/s]\u001b[A\u001b[A\n",
      "\n",
      " 89%|████████▉ | 223/250 [00:55<00:06,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|████████▉ | 224/250 [00:56<00:06,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 225/250 [00:56<00:06,  3.97it/s]\u001b[A\u001b[A\n",
      "\n",
      " 90%|█████████ | 226/250 [00:56<00:06,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 227/250 [00:56<00:05,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 91%|█████████ | 228/250 [00:57<00:05,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 229/250 [00:57<00:05,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 230/250 [00:57<00:04,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 92%|█████████▏| 231/250 [00:57<00:04,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 232/250 [00:58<00:04,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 93%|█████████▎| 233/250 [00:58<00:04,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▎| 234/250 [00:58<00:03,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 235/250 [00:58<00:03,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 94%|█████████▍| 236/250 [00:59<00:03,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▍| 237/250 [00:59<00:03,  4.03it/s]\u001b[A\u001b[A\n",
      "\n",
      " 95%|█████████▌| 238/250 [00:59<00:02,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 239/250 [00:59<00:02,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▌| 240/250 [01:00<00:02,  4.00it/s]\u001b[A\u001b[A\n",
      "\n",
      " 96%|█████████▋| 241/250 [01:00<00:02,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 242/250 [01:00<00:01,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 97%|█████████▋| 243/250 [01:00<00:01,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 244/250 [01:01<00:01,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 245/250 [01:01<00:01,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 98%|█████████▊| 246/250 [01:01<00:00,  4.02it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 247/250 [01:01<00:00,  4.01it/s]\u001b[A\u001b[A\n",
      "\n",
      " 99%|█████████▉| 248/250 [01:02<00:00,  3.98it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████▉| 249/250 [01:02<00:00,  3.99it/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|██████████| 250/250 [01:02<00:00,  4.00it/s]\u001b[A\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных предсказаний на валидационной выборке: 80.64%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Валидация\n",
    "# Переводим модель в evaluation mode\n",
    "model.eval()\n",
    "probas = []\n",
    "valid_preds, valid_labels = [], []\n",
    "\n",
    "for batch in tqdm(test_dataloader):   \n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
    "    # Это ускорит процесс предсказания меток для валидационных данных.\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
    "#     print(len(logits))\n",
    "#     batch_probas = np.array(torch.softmax(logits[0], dim=1)[:, 1])\n",
    "    logits = logits[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "#     print (label_ids.shape)\n",
    "    batch_probas = softmax(logits, axis=1)[:, 1]\n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "#     batch_labels = np.concatenate(label_ids)\n",
    "    batch_labels = np.array(label_ids)\n",
    "\n",
    "#     print (batch_probas.shape)\n",
    "#     print (batch_labels.shape)\n",
    "    \n",
    "    probas.extend(batch_probas)\n",
    "    valid_preds.extend(batch_preds)\n",
    "    valid_labels.extend(batch_labels)\n",
    "\n",
    "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
    "    accuracy_score(valid_labels, valid_preds) * 100\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71725  0.129    0.064625 0.089125] [0.15375] [0.84625]\n",
      "Custom model\n",
      "57.96747967479675 % of toxic comments were predicted correctly\n",
      "42.03252032520325 % of toxic comments were marked non-toxic\n",
      "84.75627769571639 % of non-toxic comments were predicted correctly\n",
      "15.243722304283605 % of non-toxic comments were marked toxic\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(valid_labels, valid_preds).ravel()\n",
    "\n",
    "valid_labels = np.array(valid_labels)\n",
    "print(np.array((tn, fp, fn, tp)) / valid_labels.shape[0],\n",
    "      valid_labels.sum() / valid_labels.shape,\n",
    "      (valid_labels.shape[0] - valid_labels.sum()) / valid_labels.shape)\n",
    "\n",
    "n_toxic = valid_labels.sum()\n",
    "n_non_toxic = valid_labels.shape[0] - valid_labels.sum()\n",
    "\n",
    "print(\"Custom model\")\n",
    "print((tp / n_toxic).item() * 100, \"% of toxic comments were predicted correctly\")\n",
    "print((fn / n_toxic).item() * 100, \"% of toxic comments were marked non-toxic\")\n",
    "print((tn / n_non_toxic).item() * 100, \"% of non-toxic comments were predicted correctly\")\n",
    "print((fp / n_non_toxic).item() * 100, \"% of non-toxic comments were marked toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7136187868525657"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sklearn\n",
    "sklearn.metrics.roc_auc_score(valid_labels, valid_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8000\n",
      "1753\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f19871e2e50>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# print(len(valid_labels), len(valid_preds))\n",
    "# print(valid_labels[0:10])\n",
    "# print(valid_preds[0:10])\n",
    "print (len(probas))\n",
    "\n",
    "fpr, tpr, _ = roc_curve(valid_labels, probas)\n",
    "print(len(fpr))\n",
    "plt.plot(fpr, tpr)\n",
    "# plt.plot (roc_curve(valid_labels, valid_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence in sentences:\n",
    "#     sentence = sentence.replace('\\\"', '')\n",
    "#     sentence = sentence.replace('\\n', '')\n",
    "#     sentence = sentence.lower()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = '\"Some sentence\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a.replace(\"\\\"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_len(x):\n",
    "#     return len(x.split())\n",
    "\n",
    "# train_data_toxic_comment[\"len\"] = train_data_toxic_comment[\"comment_text\"].apply(make_len)\n",
    "# train_data_toxic_comment[\"len\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_toxic_comment.count() - no missing values\n",
    "# train_data_toxic_comment.nunique() - no repeated comments\n",
    "# train_data_toxic_comment['toxic'].value_counts() - imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_unintended_bias = pd.read_csv(\"./Data/jigsaw-unintended-bias-train.csv\")\n",
    "# # train_data_unintended_bias.count() - there are missing values in columns which describe person from the comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of NaNs here, so I will replace them with something interesting. Some features are from 0 and 1, another are strictly categorical. We still have much more good comments than toxic ones - so again imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # convert \"approved\" to 1 and \"rejected\" to 0\n",
    "# train_data_unintended_bias[\"rating\"] = train_data_unintended_bias[\"rating\"].apply(lambda x: int(x == \"approved\"))\n",
    "\n",
    "# # 8:32 - there are columns which describe person from the comment\n",
    "# categorical_mean = train_data_unintended_bias.iloc[:, 8:32].mean()\n",
    "# train_data_unintended_bias.iloc[:, 8:32] = train_data_unintended_bias.iloc[:, 8:32].fillna(categorical_mean)\n",
    "\n",
    "# train_data_unintended_bias[\"len\"] = train_data_unintended_bias[\"comment_text\"].apply(make_len)\n",
    "# train_data_unintended_bias[\"len\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_unintended_bias.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
