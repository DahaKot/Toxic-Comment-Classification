{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm as tqdm\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments_train = pd.read_csv(\"./Data/jigsaw-toxic-comment-train.csv\")\n",
    "comments_test  = pd.read_csv(\"./Data/validation.csv\")\n",
    "bias_train = pd.read_csv(\"./Data/jigsaw-unintended-bias-train.csv\")\n",
    "\n",
    "# drop unneeded columns right away\n",
    "bias_train = bias_train.iloc[:, :3]\n",
    "comments_train = comments_train.iloc[:, :3]\n",
    "# print (\"Train : \", len(comments_train), \"Test : \", len(comments_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0000997932d777bf</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic\n",
       "0  0000997932d777bf  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0\n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comments_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_toxic_comment['comment_text'] = [train_data_toxic_comment['comment_text'].replace('\\\"', '')]\n",
    "# train_data_toxic_comment['comment_text'] = train_data_toxic_comment['comment_text'].replace('\\n', '')\n",
    "# train_data_toxic_comment['comment_text'] = train_data_toxic_comment['comment_text'].lower()\n",
    "\n",
    "\n",
    "# comments_train['comment_text'] = [sent.replace('\\\"', '') for sent in comments_train['comment_text']]\n",
    "# comments_train['comment_text'] = [sent.replace('\\n', '') for sent in comments_train['comment_text']]\n",
    "# comments_train['comment_text'] = [sent.lower()           for sent in comments_train['comment_text']]\n",
    "# comments_train['comment_text'] = [sent[:512]             for sent in comments_train['comment_text']]\n",
    "\n",
    "# comments_test['comment_text'] = [sent.replace('\\\"', '') for sent in comments_test['comment_text']]\n",
    "# comments_test['comment_text'] = [sent.replace('\\n', '') for sent in comments_test['comment_text']]\n",
    "# comments_test['comment_text'] = [sent.lower()           for sent in comments_test['comment_text']]\n",
    "# comments_test['comment_text'] = [sent[:512]             for sent in comments_test['comment_text']]\n",
    "\n",
    "# make_labels is similar to round but now we control what 0.5 is equal to\n",
    "def make_labels(x):\n",
    "    for i in range(x.shape[0]):\n",
    "        x[i] = 0 if x[i] <= 0.5 else 1\n",
    "    return x\n",
    "\n",
    "# bias_train[\"toxic\"] = make_labels(bias_train[\"toxic\"])\n",
    "bias_train[\"toxic\"] = bias_train[\"toxic\"].round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity fraction in train:  0.06285331763999694\n",
      "toxicity fraction in test:  0.15375\n"
     ]
    }
   ],
   "source": [
    "def preprocess(sentence):\n",
    "    sentence = sentence.replace('\\\"', '')\n",
    "    sentence = sentence.replace('\\n', '')\n",
    "    sentence = sentence.lower()\n",
    "    sentence = sentence[:512]\n",
    "    return sentence\n",
    "\n",
    "comments_train = pd.concat([comments_train, bias_train])\n",
    "\n",
    "comments_train['comment_text'] = comments_train['comment_text'].apply(preprocess)\n",
    "comments_test['comment_text']  = comments_test['comment_text'].apply(preprocess)\n",
    "print(\"toxicity fraction in train: \", comments_train['toxic'].value_counts()[1] / comments_train['toxic'].count())\n",
    "print(\"toxicity fraction in test: \", comments_test['toxic'].value_counts()[1] / comments_test['toxic'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "toxicity fraction in train:  0.18212674309237878\n",
      "toxicity fraction in test:  0.15375\n"
     ]
    }
   ],
   "source": [
    "# this cell is dealing with class imbalance\n",
    "# if you do not agree on the method - change it\n",
    "toxic = comments_train[comments_train[\"toxic\"] == 1]\n",
    "untoxic = comments_train[comments_train[\"toxic\"] == 0].sample(600000)\n",
    "\n",
    "comments_train = pd.concat((toxic, untoxic))\n",
    "# extra_toxic_comments = comments_train[comments_train[\"toxic\"] == 1].sample(10000)\n",
    "# comments_train = pd.concat([comments_train, extra_toxic_comments])\n",
    "\n",
    "print(\"toxicity fraction in train: \", comments_train['toxic'].value_counts()[1] / comments_train['toxic'].count())\n",
    "print(\"toxicity fraction in test: \", comments_test['toxic'].value_counts()[1] / comments_test['toxic'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences train :  733610 , test :  8000\n",
      "Example :  [CLS] mesaj sayfama yaptığınız müdahale vandalizm olarak kabul edilir. lütfen reklam yapmak için kullanıcıların sayfalarını değiştirmeyinizdelamorena  [SEP]\n"
     ]
    }
   ],
   "source": [
    "sentences_train = np.array(comments_train['comment_text'].values)\n",
    "sentences_test  = np.array(comments_test ['comment_text'].values)\n",
    "sentences_train = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences_train]\n",
    "sentences_test  = [\"[CLS] \" + sentence + \" [SEP]\" for sentence in sentences_test]\n",
    "\n",
    "labels_train = np.array(comments_train['toxic'])\n",
    "labels_test  = np.array(comments_test['toxic'])\n",
    "\n",
    "assert len(sentences_train) == len(labels_train)\n",
    "assert len(sentences_test)  == len(labels_test)\n",
    "\n",
    "print (\"Number of sentences train : \", len(sentences_train), \", test : \", len(sentences_test))\n",
    "print (\"Example : \", sentences_test[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 733610/733610 [08:35<00:00, 1422.94it/s]\n",
      "100%|██████████| 8000/8000 [00:06<00:00, 1237.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', 'co', '##cks', '##uck', '##er', 'before', 'you', 'pis', '##s', 'around', 'on', 'my', 'work', '[SEP]']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from pytorch_transformers import BertTokenizer, BertConfig\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "\n",
    "tokenized_texts_tr = [tokenizer.tokenize(sent) for sent in tqdm(sentences_train)]\n",
    "tokenized_texts_te = [tokenizer.tokenize(sent) for sent in tqdm(sentences_test)]\n",
    "print (tokenized_texts_tr[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 5505\n",
    "# print (\"Language : [\", comments_test['lang'][i], \"]\")\n",
    "# print (sentences_test[i])\n",
    "# print(tokenized_texts[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ids_and_masks(tokenizer, tokenized_texts):\n",
    "    input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tqdm(tokenized_texts)]\n",
    "    input_ids = pad_sequences(\n",
    "        input_ids,\n",
    "        maxlen=512,\n",
    "        dtype=\"long\",\n",
    "        truncating=\"post\",\n",
    "        padding=\"post\"\n",
    "    )\n",
    "    attention_masks = [[float(i>0) for i in seq] for seq in tqdm(input_ids)]\n",
    "    print (\"Dataset shape : \", input_ids.shape)\n",
    "    return input_ids, attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 645817/2125743 [00:28<00:57, 25867.79it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (514 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 2125743/2125743 [01:34<00:00, 22562.60it/s]\n",
      "  9%|▊         | 181361/2125743 [02:45<1677:16:38,  3.11s/it]"
     ]
    }
   ],
   "source": [
    "input_ids_tr, attention_masks_tr = ids_and_masks(tokenizer, tokenized_texts_tr)\n",
    "input_ids_te, attention_masks_te = ids_and_masks(tokenizer, tokenized_texts_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids_tr = [tokenizer.convert_tokens_to_ids(x) for x in tqdm(tokenized_texts_tr)]\n",
    "# input_ids_tr = pad_sequences(\n",
    "#     input_ids_tr,\n",
    "#     maxlen=512,\n",
    "#     dtype=\"long\",\n",
    "#     truncating=\"post\",\n",
    "#     padding=\"post\"\n",
    "# )\n",
    "# print (input_ids_tr.shape)\n",
    "# attention_masks_tr = [[float(i>0) for i in seq] for seq in input_ids_tr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_ids_te = [tokenizer.convert_tokens_to_ids(x) for x in tqdm(tokenized_texts_te)]\n",
    "# input_ids_te = pad_sequences(\n",
    "#     input_ids_te,\n",
    "#     maxlen=512,\n",
    "#     dtype=\"long\",\n",
    "#     truncating=\"post\",\n",
    "#     padding=\"post\"\n",
    "# )\n",
    "# print (input_ids_te.shape)\n",
    "# attention_masks_te = [[float(i>0) for i in seq] for seq in input_ids_te]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs = torch.tensor(input_ids_tr)\n",
    "train_labels = torch.tensor(labels_train)\n",
    "train_masks  = torch.tensor(attention_masks_tr)\n",
    "\n",
    "test_inputs  = torch.tensor(input_ids_te)\n",
    "test_labels  = torch.tensor(labels_test)\n",
    "test_masks   = torch.tensor(attention_masks_te)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_dataloader = DataLoader(\n",
    "    train_data,\n",
    "    sampler=RandomSampler(train_data),\n",
    "    batch_size=2\n",
    ")\n",
    "\n",
    "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
    "test_dataloader = DataLoader(\n",
    "    test_data,\n",
    "    sampler=SequentialSampler(test_data),\n",
    "    batch_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_transformers import AdamW, BertForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 625/625 [00:00<00:00, 104079.09B/s]\n",
      " 11%|█         | 78753792/714314041 [02:50<21:56, 482727.70B/s]  "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-aa33a9a08858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-multilingual-cased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    512\u001b[0m         \u001b[0;31m# redirect to the cache, if necessary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    513\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 514\u001b[0;31m             \u001b[0mresolved_archive_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcached_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marchive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    515\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mEnvironmentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpretrained_model_name_or_path\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpretrained_model_archive_map\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_transformers/file_utils.py\u001b[0m in \u001b[0;36mcached_path\u001b[0;34m(url_or_filename, cache_dir, force_download, proxies)\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mparsed\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscheme\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'http'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'https'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m's3'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0;31m# URL, so get it from the cache (downloading if necessary)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 118\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mget_from_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcache_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcache_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_download\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_download\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    119\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl_or_filename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m         \u001b[0;31m# File, and it exists.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_transformers/file_utils.py\u001b[0m in \u001b[0;36mget_from_cache\u001b[0;34m(url, cache_dir, force_download, proxies)\u001b[0m\n\u001b[1;32m    242\u001b[0m                 \u001b[0ms3_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m                 \u001b[0mhttp_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxies\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mproxies\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    245\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# we are copying the file before closing it, so flush to avoid truncation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pytorch_transformers/file_utils.py\u001b[0m in \u001b[0;36mhttp_get\u001b[0;34m(url, temp_file, proxies)\u001b[0m\n\u001b[1;32m    182\u001b[0m     \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent_length\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcontent_length\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m     \u001b[0mprogress\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0munit\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"B\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtotal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 184\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# filter out keep-alive new chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m             \u001b[0mprogress\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/requests/models.py\u001b[0m in \u001b[0;36mgenerate\u001b[0;34m()\u001b[0m\n\u001b[1;32m    748\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'stream'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    749\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    751\u001b[0m                         \u001b[0;32myield\u001b[0m \u001b[0mchunk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mProtocolError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mstream\u001b[0;34m(self, amt, decode_content)\u001b[0m\n\u001b[1;32m    562\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    563\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_fp_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 564\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode_content\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdecode_content\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    566\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/response.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt, decode_content, cache_content)\u001b[0m\n\u001b[1;32m    505\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                 \u001b[0mcache_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfp_closed\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34mb\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m                 if (\n\u001b[1;32m    509\u001b[0m                     \u001b[0mamt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, amt)\u001b[0m\n\u001b[1;32m    455\u001b[0m             \u001b[0;31m# Amount is given, implement using readinto\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m             \u001b[0mb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/http/client.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    499\u001b[0m         \u001b[0;31m# connection, and the user is reading more bytes than will be provided\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m         \u001b[0;31m# (for example, reading in 1k chunks)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m         \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mn\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0;31m# Ideally, we would raise IncompleteRead if the content-length\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 589\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    590\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    591\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/urllib3/contrib/pyopenssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    311\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 313\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconnection\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    314\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOpenSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSysCallError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msuppress_ragged_eofs\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Unexpected EOF\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/OpenSSL/SSL.py\u001b[0m in \u001b[0;36mrecv_into\u001b[0;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[1;32m   1837\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_peek\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1839\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSSL_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1840\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_raise_ssl_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ssl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1841\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-multilingual-cased\", num_labels=2)\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_optimizer = list(model.named_parameters())\n",
    "no_decay = ['bias', 'gamma', 'beta']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
    "     'weight_decay_rate': 0.0}\n",
    "]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-7c15876099c0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Backward pass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# Обновляем параметры и делаем шаг используя посчитанные градиенты\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    196\u001b[0m                 \u001b[0mproducts\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mDefaults\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m         \"\"\"\n\u001b[0;32m--> 198\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m     99\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "\n",
    "# Будем сохранять loss во время обучения\n",
    "# и рисовать график в режиме реального времени\n",
    "train_loss_set = []\n",
    "train_loss = 0\n",
    "\n",
    "\n",
    "# Обучение\n",
    "# Переводим модель в training mode\n",
    "model.train()\n",
    "\n",
    "\n",
    "for step, batch in enumerate(train_dataloader):\n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # если не сделать .zero_grad(), градиенты будут накапливаться\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    # Forward pass\n",
    "    loss = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n",
    "\n",
    "    train_loss_set.append(loss[0].item())  \n",
    "    \n",
    "    # Backward pass\n",
    "    loss[0].backward()\n",
    "    \n",
    "    # Обновляем параметры и делаем шаг используя посчитанные градиенты\n",
    "    optimizer.step()\n",
    "\n",
    "    # Обновляем loss\n",
    "    train_loss += loss[0].item()\n",
    "    \n",
    "    # Рисуем график\n",
    "    clear_output(True)\n",
    "    plt.plot(train_loss_set)\n",
    "    plt.title(\"Training loss\")\n",
    "    plt.xlabel(\"Batch\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.show()\n",
    "    \n",
    "print(\"Loss на обучающей выборке: {0:.5f}\".format(train_loss / len(train_dataloader)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4000/4000 [02:48<00:00, 23.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Процент правильных предсказаний на валидационной выборке: 84.62%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Валидация\n",
    "# Переводим модель в evaluation mode\n",
    "model.eval()\n",
    "\n",
    "valid_preds, valid_labels = [], []\n",
    "\n",
    "for batch in tqdm(test_dataloader):   \n",
    "    # добавляем батч для вычисления на GPU\n",
    "    batch = tuple(t.to(device) for t in batch)\n",
    "    \n",
    "    # Распаковываем данные из dataloader\n",
    "    b_input_ids, b_input_mask, b_labels = batch\n",
    "    \n",
    "    # При использовании .no_grad() модель не будет считать и хранить градиенты.\n",
    "    # Это ускорит процесс предсказания меток для валидационных данных.\n",
    "    with torch.no_grad():\n",
    "        logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n",
    "\n",
    "    # Перемещаем logits и метки классов на CPU для дальнейшей работы\n",
    "    logits = logits[0].detach().cpu().numpy()\n",
    "    label_ids = b_labels.to('cpu').numpy()\n",
    "    \n",
    "#     print (label_ids.shape)\n",
    "    batch_preds = np.argmax(logits, axis=1)\n",
    "#     batch_labels = np.concatenate(label_ids)\n",
    "    batch_labels = np.array(label_ids)\n",
    "\n",
    "    valid_preds.extend(batch_preds)\n",
    "    valid_labels.extend(batch_labels)\n",
    "\n",
    "print(\"Процент правильных предсказаний на валидационной выборке: {0:.2f}%\".format(\n",
    "    accuracy_score(valid_labels, valid_preds) * 100\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "tn, fp, fn, tp = confusion_matrix(torch.argmax(model.predict(x_test), dim = 1), y_test).ravel()\n",
    "\n",
    "print((tn, fp, fn, tp), y_test.sum(), (y_test.shape[0] - y_test.sum()))\n",
    "\n",
    "print(\"Custom model\")\n",
    "print((tp / y_test.sum()).item() * 100, \"% of toxic comments were predicted correctly\")\n",
    "print((fn / (y_test.shape[0] - y_test.sum())).item() * 100, \"% of toxic comments were marked non-toxic\")\n",
    "print((tn / (y_test.shape[0] - y_test.sum())).item() * 100, \"% of non-toxic comments were predicted correctly\")\n",
    "print((fp / y_test.sum()).item() * 100, \"% of non-toxic comments were marked toxic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for sentence in sentences:\n",
    "#     sentence = sentence.replace('\\\"', '')\n",
    "#     sentence = sentence.replace('\\n', '')\n",
    "#     sentence = sentence.lower()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = '\"Some sentence\"'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a.replace(\"\\\"\", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_len(x):\n",
    "    return len(x.split())\n",
    "\n",
    "train_data_toxic_comment[\"len\"] = train_data_toxic_comment[\"comment_text\"].apply(make_len)\n",
    "train_data_toxic_comment[\"len\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_toxic_comment.count() - no missing values\n",
    "# train_data_toxic_comment.nunique() - no repeated comments\n",
    "# train_data_toxic_comment['toxic'].value_counts() - imbalanced classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_unintended_bias = pd.read_csv(\"./Data/jigsaw-unintended-bias-train.csv\")\n",
    "# train_data_unintended_bias.count() - there are missing values in columns which describe person from the comment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lot of NaNs here, so I will replace them with something interesting. Some features are from 0 and 1, another are strictly categorical. We still have much more good comments than toxic ones - so again imbalanced classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert \"approved\" to 1 and \"rejected\" to 0\n",
    "train_data_unintended_bias[\"rating\"] = train_data_unintended_bias[\"rating\"].apply(lambda x: int(x == \"approved\"))\n",
    "\n",
    "# 8:32 - there are columns which describe person from the comment\n",
    "categorical_mean = train_data_unintended_bias.iloc[:, 8:32].mean()\n",
    "train_data_unintended_bias.iloc[:, 8:32] = train_data_unintended_bias.iloc[:, 8:32].fillna(categorical_mean)\n",
    "\n",
    "train_data_unintended_bias[\"len\"] = train_data_unintended_bias[\"comment_text\"].apply(make_len)\n",
    "train_data_unintended_bias[\"len\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_unintended_bias.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
